**Interviewer:** Good morning, Sunita. Thank you for joining this interview. Could you start by telling me about your background and your role as a teaching assistant?

**Sunita:** Good morning. I’m Sunita Yadav, a final-year PhD scholar in humanities. My research focuses on gender studies, and I’ve been assisting in undergraduate humanities courses for the past three years. My work involves mentoring students, grading essays, and leading discussion groups. It’s a role I deeply enjoy because it allows for meaningful interactions with students.

**Interviewer:** That sounds rewarding. Could you share your experience with AI tools in your work as a teaching assistant?

**Sunita:** To be honest, I’ve rarely used AI tools. Most of my work relies on manual grading and personal engagement with students. I’ve experimented with plagiarism checkers, but that’s about it. In humanities, the focus is often on subjective analysis, and I find it hard to see how AI could add value in such a context.

**Interviewer:** That’s an interesting perspective. What concerns you most about using AI in your work?

**Sunita:** My main concern is that AI feels impersonal. Grading an essay, for instance, is not just about checking grammar or structure—it’s about understanding the argument, the creativity, and the nuances of the student’s perspective. I’m not convinced that an AI tool can grasp those subtleties. I worry that relying on AI might compromise the depth and quality of feedback students receive.

**Interviewer:** That’s a valid concern. Are there specific challenges you face with traditional methods that you think AI could help address?

**Sunita:** Grading is definitely time-consuming, especially with large class sizes. I can see how AI might help speed up the process for routine tasks like checking grammar or structure. But I still believe the core evaluation, particularly in humanities, needs a human touch. Another challenge is that students sometimes struggle with basic writing skills. While AI might help them with grammar, I think the mentoring aspect—teaching them how to improve—is more effective when done personally.

**Interviewer:** That’s an interesting balance. Do you think AI could complement your teaching rather than replace personal interactions?

**Sunita:** Possibly. If AI tools could assist with the technical aspects—like identifying common writing errors or generating basic summaries—it might save time and allow me to focus on the more nuanced parts of grading and mentoring. But I’d still want to review everything myself before providing feedback. For me, the value of teaching lies in the personal connection and the opportunity to guide students in their thought process.

**Interviewer:** That’s a thoughtful perspective. Do you think AI has a place in humanities courses at all?

**Sunita:** It could, in a limited way. For example, AI might be useful for generating study guides or summarizing long readings, which can help students manage their workload. It could also provide quick grammar and style corrections, especially for students who struggle with language barriers. But when it comes to deeper, subjective work—like essays or research papers—I feel the human element is irreplaceable.

**Interviewer:** That makes sense. Have you encountered any resistance from students when it comes to using AI tools?

**Sunita:** Interestingly, some students are quite eager to use AI tools, especially for grammar checks or drafting ideas. But I’ve also noticed that many of them struggle to understand the limitations of these tools. For instance, they might rely too much on AI for content generation without critically evaluating the results. This is something I emphasize in my mentoring—tools are useful, but critical thinking is irreplaceable.

**Interviewer:** That’s an important point. Do you see any risks associated with over-reliance on AI in education?

**Sunita:** Absolutely. One major risk is the loss of critical thinking skills. If students use AI to do the heavy lifting, they might not develop the ability to analyze or construct arguments themselves. Another concern is ethical—AI tools can sometimes produce biased or misleading results, and students may not always recognize these issues. It’s crucial to teach them how to use AI responsibly.

**Interviewer:** Those are valid concerns. Lastly, do you have any advice for educators or institutions considering the integration of AI in education?

**Sunita:** My advice would be to use AI cautiously and in a way that complements traditional teaching methods. It’s important to set clear boundaries for its use, especially in fields like humanities where subjectivity and creativity are central. Institutions should also provide training for both faculty and students to ensure everyone understands the capabilities and limitations of these tools. Most importantly, we should never lose sight of the human aspect of education—it’s what makes teaching and learning meaningful.

**Interviewer:** Thank you, Sunita, for sharing your experiences and insights. This has been a very enlightening conversation.

**Sunita:** Thank you! It was a pleasure to discuss these topics. I hope my perspective adds to the larger conversation about AI in education.